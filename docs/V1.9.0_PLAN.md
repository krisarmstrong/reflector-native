# v1.9.0 - macOS BPF Optimizations (Quick Win)

**Timeline**: 1-2 weeks
**Expected Improvement**: 50 Mbps → **60-75 Mbps** (20-50%)
**Effort**: Low
**Risk**: Low
**Focus**: Extract maximum performance from existing BPF architecture

---

## Goals

1. Squeeze every possible optimization from `/dev/bpf` implementation
2. Achieve 60-75 Mbps sustained throughput on macOS
3. Prepare codebase for v2.0.0 Network Extension migration
4. Zero breaking changes (drop-in replacement)

---

## Optimization Checklist

### 1. BPF Buffer Size Tuning

**Current**: Using default buffer size
**Target**: Maximum allowed by macOS kernel

```c
// Find optimal buffer size
#define BPF_MAX_BUFFER (1024 * 1024)  // 1 MB

int buf_size = BPF_MAX_BUFFER;
if (ioctl(fd, BIOCSBLEN, &buf_size) < 0) {
    // Try progressively smaller sizes
    buf_size = 512 * 1024;
    if (ioctl(fd, BIOCSBLEN, &buf_size) < 0) {
        buf_size = 256 * 1024;
        ioctl(fd, BIOCSBLEN, &buf_size);
    }
}
```

**Expected Impact**: 5-10% improvement
**File**: `src/dataplane/macos_bpf/bpf_platform.c`

---

### 2. Immediate Mode (Disable Buffering)

**Current**: Packets buffered in kernel
**Target**: Immediate delivery to userspace

```c
// Enable immediate mode for lowest latency
int immediate = 1;
if (ioctl(fd, BIOCIMMEDIATE, &immediate) < 0) {
    reflector_log(LOG_WARN, "Failed to enable immediate mode");
}
```

**Trade-off**: Lower latency but slightly higher CPU usage
**Expected Impact**: 5-10% improvement
**File**: `src/dataplane/macos_bpf/bpf_platform.c`

---

### 3. Non-Blocking I/O with kqueue

**Current**: Blocking read() calls
**Target**: Event-driven I/O with kqueue

```c
#include <sys/event.h>

// Set non-blocking
int flags = fcntl(fd, F_GETFL, 0);
fcntl(fd, F_SETFL, flags | O_NONBLOCK);

// Create kqueue for event notification
int kq = kqueue();
struct kevent event;
EV_SET(&event, fd, EVFILT_READ, EV_ADD | EV_ENABLE, 0, 0, NULL);
kevent(kq, &event, 1, NULL, 0, NULL);

// Event loop
while (running) {
    struct kevent events[1];
    int nev = kevent(kq, NULL, 0, events, 1, &timeout);

    if (nev > 0) {
        // Data available, read immediately
        ssize_t n = read(fd, buffer, buffer_size);
        // Process packets...
    }
}
```

**Expected Impact**: 10-15% improvement (reduced idle CPU)
**File**: `src/dataplane/macos_bpf/bpf_platform.c`

---

### 4. Optimized Read Batch Size

**Current**: Single read() per packet
**Target**: Read multiple packets per syscall

```c
// BPF can return multiple packets in one read
uint8_t buffer[BPF_MAX_BUFFER];
ssize_t n = read(fd, buffer, sizeof(buffer));

// Parse BPF header to extract multiple packets
struct bpf_hdr *bpf_pkt = (struct bpf_hdr *)buffer;
while ((uint8_t *)bpf_pkt < buffer + n) {
    uint8_t *pkt_data = (uint8_t *)bpf_pkt + bpf_pkt->bh_hdrlen;
    uint32_t pkt_len = bpf_pkt->bh_caplen;

    // Process packet...

    // Next packet (aligned)
    bpf_pkt = (struct bpf_hdr *)((uint8_t *)bpf_pkt + BPF_WORDALIGN(bpf_pkt->bh_hdrlen + pkt_len));
}
```

**Expected Impact**: 10-20% improvement (amortized syscall cost)
**File**: `src/dataplane/macos_bpf/bpf_platform.c`

---

### 5. Write Coalescing (Batch Writes)

**Current**: write() per packet
**Target**: Batch multiple packets into single write()

```c
// Accumulate packets into write buffer
uint8_t write_buffer[BPF_MAX_BUFFER];
size_t write_offset = 0;

for (int i = 0; i < num_tx; i++) {
    if (write_offset + pkts_tx[i].len > sizeof(write_buffer)) {
        // Flush current buffer
        write(fd, write_buffer, write_offset);
        write_offset = 0;
    }

    memcpy(write_buffer + write_offset, pkts_tx[i].data, pkts_tx[i].len);
    write_offset += pkts_tx[i].len;
}

// Flush remaining
if (write_offset > 0) {
    write(fd, write_buffer, write_offset);
}
```

**Expected Impact**: 5-10% improvement
**File**: `src/dataplane/macos_bpf/bpf_platform.c`

---

### 6. BPF Filter Optimization

**Current**: Minimal/no BPF filter
**Target**: Kernel-level filtering to reduce userspace packets

```c
// Compile BPF filter for UDP packets only
struct bpf_program bpf_prog;
char filter_exp[] = "udp";  // Only pass UDP packets

if (pcap_compile(pcap, &bpf_prog, filter_exp, 1, PCAP_NETMASK_UNKNOWN) == 0) {
    // Apply filter to BPF device
    if (ioctl(fd, BIOCSETF, &bpf_prog) < 0) {
        reflector_log(LOG_WARN, "Failed to set BPF filter");
    }
    pcap_freecode(&bpf_prog);
}
```

**Expected Impact**: 10-15% improvement (filters out non-UDP traffic in kernel)
**File**: `src/dataplane/macos_bpf/bpf_platform.c`

---

### 7. Header Cache (Avoid Repeated Lookups)

**Current**: Parse BPF header for each packet
**Target**: Cache frequently accessed values

```c
// Cache BPF header info
typedef struct {
    int hdr_len;
    int alignment;
    int max_packets_per_read;
} bpf_cache_t;

bpf_cache_t cache = {
    .hdr_len = sizeof(struct bpf_hdr),
    .alignment = BPF_ALIGNMENT,
    .max_packets_per_read = BPF_MAX_BUFFER / MIN_ITO_PACKET_LEN
};
```

**Expected Impact**: 2-5% improvement
**File**: `src/dataplane/macos_bpf/bpf_platform.c`

---

### 8. Memory Pool for Packet Buffers

**Current**: Dynamic allocation per packet
**Target**: Pre-allocated memory pool

```c
// Pre-allocate packet buffer pool
typedef struct {
    uint8_t *buffers;
    uint32_t buffer_size;
    uint32_t num_buffers;
    uint32_t next_free;
} pkt_pool_t;

pkt_pool_t *pool_create(uint32_t num_buffers, uint32_t buffer_size) {
    pkt_pool_t *pool = malloc(sizeof(pkt_pool_t));
    pool->buffers = malloc(num_buffers * buffer_size);
    pool->buffer_size = buffer_size;
    pool->num_buffers = num_buffers;
    pool->next_free = 0;
    return pool;
}
```

**Expected Impact**: 3-5% improvement (reduced malloc/free overhead)
**File**: `src/dataplane/macos_bpf/bpf_platform.c`

---

### 9. CPU Affinity (Leverage GCD from v1.8.0)

**Current**: GCD handles scheduling
**Target**: Ensure worker stays on performance cores (Apple Silicon)

```c
// Request high QoS to stay on performance cores
dispatch_queue_attr_t attr = dispatch_queue_attr_make_with_qos_class(
    DISPATCH_QUEUE_SERIAL,
    QOS_CLASS_USER_INTERACTIVE,  // Already doing this
    0
);

// Additional: Request specific performance characteristics
dispatch_set_target_queue(queue, dispatch_get_global_queue(QOS_CLASS_USER_INTERACTIVE, 0));
```

**Expected Impact**: 5-10% improvement on Apple Silicon
**File**: `src/dataplane/common/core.c`

---

## Implementation Plan

### Week 1: Core Optimizations

**Day 1-2**: BPF buffer tuning & immediate mode
- [ ] Implement buffer size detection
- [ ] Enable immediate mode
- [ ] Test on Apple Silicon and Intel

**Day 3-4**: Non-blocking I/O with kqueue
- [ ] Implement kqueue event loop
- [ ] Replace blocking read() with event-driven model
- [ ] Benchmark latency improvements

**Day 5**: Batch read/write optimization
- [ ] Implement multi-packet read parsing
- [ ] Implement write coalescing
- [ ] Measure syscall reduction

### Week 2: Advanced Optimizations & Testing

**Day 6-7**: BPF filter and memory pool
- [ ] Compile and apply UDP-only BPF filter
- [ ] Implement packet buffer pool
- [ ] Profile memory allocation overhead

**Day 8-9**: Performance testing
- [ ] Benchmark on Apple Silicon (M1/M2/M3)
- [ ] Benchmark on Intel Mac
- [ ] Compare against v1.8.1 baseline

**Day 10**: Documentation & release
- [ ] Update CHANGELOG
- [ ] Document new BPF optimizations
- [ ] Update performance benchmarks
- [ ] Tag v1.9.0 release

---

## Testing Requirements

### Performance Testing

**Target Metrics**:
- Sustained throughput: 60-75 Mbps
- Packet rate: 500,000+ pps (1500-byte packets)
- CPU usage: <80% of single core
- Latency: <2000ns per packet (50% reduction)

**Test Scenarios**:
1. 64-byte packets (worst case)
2. 1500-byte packets (typical)
3. 9000-byte jumbo frames (best case)
4. Mixed packet sizes
5. Sustained load (1+ hour)

**Hardware**:
- Apple Silicon Mac (M1/M2/M3)
- Intel Mac (for compatibility)
- LinkRunner 10G or similar traffic generator

### Regression Testing

- [ ] All existing tests pass
- [ ] No performance regression on Linux
- [ ] Backward compatible with existing configs

---

## Success Criteria

### Must Have
- ✅ 60+ Mbps sustained throughput
- ✅ Zero breaking changes
- ✅ All tests passing
- ✅ No memory leaks

### Should Have
- ✅ 70+ Mbps sustained throughput
- ✅ 30%+ improvement over v1.8.1
- ✅ Reduced CPU usage

### Nice to Have
- ✅ 75 Mbps sustained throughput
- ✅ 50%+ improvement over v1.8.1
- ✅ Sub-1500ns per-packet latency

---

## Risk Mitigation

### Risk 1: BPF Buffer Size Limits
**Mitigation**: Implement progressive fallback (1MB → 512KB → 256KB)

### Risk 2: kqueue Complexity
**Mitigation**: Keep blocking I/O as fallback option

### Risk 3: Performance Varies by Hardware
**Mitigation**: Test on multiple Mac models (Intel + Apple Silicon)

### Risk 4: Optimization Trade-offs
**Mitigation**: Make optimizations configurable via compile-time flags

---

## Files to Modify

| File | Changes | LOC |
|------|---------|-----|
| `src/dataplane/macos_bpf/bpf_platform.c` | Core BPF optimizations | 200-300 |
| `include/reflector.h` | New constants/macros | 10-20 |
| `Makefile` | Build flags | 5-10 |
| `CHANGELOG.md` | v1.9.0 entry | 20-30 |
| `docs/PERFORMANCE.md` | Updated benchmarks | 50-100 |

**Total Estimated LOC**: 300-500 lines

---

## Deliverables

1. ✅ Optimized macOS BPF implementation
2. ✅ Performance benchmarks (before/after)
3. ✅ Updated documentation
4. ✅ Release notes
5. ✅ Tagged v1.9.0 release

---

## Next Steps (Post v1.9.0)

After v1.9.0 is complete and tested:
1. Gather user feedback on 60-75 Mbps performance
2. Assess demand for v2.0.0 (500-800 Mbps)
3. Begin v2.0.0 planning if justified
4. Continue Linux AF_XDP development in parallel

---

**Status**: Ready to implement
**Priority**: High (quick win)
**Owner**: TBD
**Target Release**: Q1 2025
